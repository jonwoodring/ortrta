---
title: "heat"
author: "Jon Woodring"
date: "May 2, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Heat in dplyr #

The program is pretty much the same as the Spark version, and this is just
a stunt to show how similar the programming is.

Also, to show you how the dplyr (Spark) compiles into SQL commands.

```{r}
library(dplyr)
library(RSQLite)
library(ggplot2)

if (!dir.exists("./images"))
{
  dir.create("./images")
}
if (file.exists("./heat.db"))
{
  file.remove("./heat.db")
}
db <- src_sqlite("./heat.db", create=TRUE)
dbGetQuery(db $ con, "pragma journal=memory")
dbGetQuery(db $ con, "pragma synchronize=off")
dbGetQuery(db $ con, "pragma threads=4")
```

## grid ##

We create our is and js such that we have a list of `uid` to i, j positions.

One difference between Spark is that we have different types of joins, like
`inner_join`. 

```{r}
x <- 202
y <- 202

is <- copy_to(db, data.frame(i=1:x-1))
js <- copy_to(db, data.frame(j=1:y-1))

grid <- is %>%
  mutate(dummy = 1) %>%
  inner_join(js %>% mutate(dummy = 1)) %>%
  select(-dummy) %>%
  mutate(uid=i + j * x)
explain(grid)
grid <- grid %>%
  compute(name="grid", unique_indexes=list("uid"))
grid
```

## topology and stencil ##

For the `stencil`, we individually create each direction, somewhat similar
to how we did it in Thrust, but instead of zipping the columns together,
we union them into one table, creating the topology, `topo`.

It would be possible to zip them together, like Thrust, but that creates
a problem if you want to create topologies that aren't always 4-way. By
creating a list, i.e., (uid, adjacent) keyed by uid, we can have arbitrary
topologies, like points, triangles, tetrahedra, etc.

```{r}
non_boundary <- grid %>% 
  filter(i > 0 && i < x-1 && j > 0 && j < y-1)
left <- non_boundary %>% mutate(a=i-1, b=j) %>% select(-i, -j)
right <- non_boundary %>% mutate(a=i+1, b=j) %>%  select(-i, -j)
top <- non_boundary %>%  mutate(a=i, b=j+1) %>% select(-i, -j)
bottom <- non_boundary %>%  mutate(a=i, b=j-1) %>% select(-i, -j)
stencil <- left %>% 
  union_all(right) %>%
  union_all(top) %>%
  union_all(bottom)
topo <- stencil %>%
  left_join(grid, c("a"="i", "b"="j")) %>%
  mutate(uid=uid.x, adj=uid.y) %>%
  select(-a, -b, -i, -j, -uid.x, -uid.y)
explain(topo)
topo <- topo %>%
  compute(name="topo", indexes=list("uid"))
topo
```

## initialization ##

`dplyr` is nice in that it gives us a sampling function, `sample_n`, allowing
us to sampling from the non boundary grid points. We use the sample to
mutate them with the initial heat to union them back into the heat table,
`current`, and reduce the temperatures by key, i.e., `group_by` and 
`summarize`.

```{r}
add_random_heat <- non_boundary %>%
  collect() %>%
  sample_n(4) %>%
  mutate(heat=1) %>%
  select(-i, -j)
current <- grid %>% 
  mutate(heat=0) %>%
  select(-i, -j) %>%
  union_all(add_random_heat, copy=TRUE) %>%
  group_by(uid) %>%
  summarize(heat=sum(heat)) 
explain(current) 
current <- current %>%
  compute(name="current")
current %>% filter(heat > 0)
```

## update_step ##

The `update_step` is the same as Spark.

```{r}
update_step <- function(current)
{
  neighbors <- topo %>%
    inner_join(current, c("adj"="uid")) %>%
    mutate(heat=heat*0.125, center=uid.x) %>%
    select(-adj, -uid.x, -uid.y)
  current %>% 
    mutate(heat=heat*0.5, center=uid) %>%
    select(-uid) %>%
    union_all(neighbors) %>%
    group_by(center) %>%
    summarize(heat=sum(heat)) %>%
    mutate(uid=center)
}
explain(update_step(current))
update_step(current) %>% filter(heat > 0)
```

## write_output ##

We can directly write the output back into a table by using some SQL
to select the existing table into a new table. We can directly plot the
data since we are in R.

```{r}
write_output <- function(t)
{
  dbGetQuery(db $ con,
    paste("create table output_0_", t, 
          " as select grid.i as i, grid.j as j, heat from current, grid where current.uid = grid.uid",
          " and i > 0 and i <= ", x-2,
          " and j > 0 and j <= ", y-2, sep=""))
  tbl(db, paste("output_0_", t, sep="")) %>%
    collect() %>%
    ggplot() +
    aes(x=i, y=j, fill=heat) +
    geom_raster() +
    ggsave(paste("images/output_0_", t, ".png", sep="")) +
    scale_color_gradient()
}
```

## heat program ##

What's different here from Spark is that we use double-buffering to flip
between tables. This is because name bindings are global, and we need
to drop the old table names and rename to the existing table name.

```{r}
write_output(0)

for (t in 1:100)
{
  nexts <- update_step(current) %>% compute(name="next")
  sink <- dbGetQuery(db $ con, "drop table current")
  sink <- dbGetQuery(db $ con, "alter table next rename to current")
  current <- tbl(db, "current")
  
  if (t %% 100 == 0) write_output(t)
}
```